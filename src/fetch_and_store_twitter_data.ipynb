{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "difficult-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peripheral-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, save_json, BASE_DATA_DIR\n",
    "from twitter_requests import TwitterApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daily-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-option",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api = TwitterApi(timeline_params_path=\"timeline_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = pd.read_csv(os.path.join(BASE_DATA_DIR, \"twitter_data/candidates_20210604.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_folder_path = os.path.join(BASE_DATA_DIR, \"twitter_data/raw_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in candidates_df.iterrows():\n",
    "    print(row.full_name)\n",
    "    twitter_api.build_user_dataset(row.twitter_name, data_dir=tweet_folder_path)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-omaha",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_files = glob(f\"{tweet_folder_path}/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = []\n",
    "\n",
    "for filepath in twitter_files:\n",
    "    twitter_data.extend(load_json(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.DataFrame(twitter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"author_id\"] = twitter_df.author_id.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da95ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df[\"author_id\"] = candidates_df.twitter_name.map(lambda x: str(twitter_api.query_user_data_by_name(x)[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.merge(\n",
    "    left=twitter_df,\n",
    "    right=candidates_df,\n",
    "    on=\"author_id\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707b32d",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet_preprocessing import normalize_mentions, normalize_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7065a0",
   "metadata": {},
   "source": [
    "## Normalize user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46234dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name_mapping_path = os.path.join(BASE_DATA_DIR, \"twitter_data/user_name_mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_mentions(twitter_df, twitter_api, user_name_mapping_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440ec82",
   "metadata": {},
   "source": [
    "## Normalize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea22453",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_mapping = {\n",
    "    \"BuReg\": \"Bundesregierung\",\n",
    "    \"üá©üá™\": \"Deutschland\",\n",
    "    \"&amp;\": \"und\",\n",
    "    \"#\": \"\",\n",
    "    r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô]))\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"cleaned_text\"] = twitter_df.cleaned_text.map(lambda x: normalize_tokens(x, token_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d951fc5",
   "metadata": {},
   "source": [
    "# Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_pickle(os.path.join(BASE_DATA_DIR, \"twitter_data/processed_datasets/twitter_df_20210604.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03883741",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_pickle(os.path.join(BASE_DATA_DIR, \"twitter_data/processed_datasets/twitter_df_20210604.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca298f",
   "metadata": {},
   "source": [
    "# Upload to Elastic Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_wrappers.haystack_elasticsearch_fix import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7697655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/04/2021 12:23:01 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
      "06/04/2021 12:23:01 - INFO - faiss.loader -   Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "06/04/2021 12:23:01 - INFO - faiss.loader -   Loading faiss.\n",
      "06/04/2021 12:23:01 - INFO - faiss.loader -   Successfully loaded faiss.\n",
      "06/04/2021 12:23:08 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89a9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'https://a5ca101c4ed9428faea3b97e4e56bf91.us-west1.gcp.cloud.es.io'\n",
    "port = 9243\n",
    "credentials_path = \"credentials-65d862-2021-May-07--21_21_57.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc11087",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(credentials_path, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        es_username = row[\"username\"].strip()\n",
    "        es_password = row[\"password \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ae56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\n",
    "                hosts=[host],\n",
    "                port=port,\n",
    "                http_auth=(es_username, es_password),\n",
    "                scheme=\"http\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ElsticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = ElasticsearchDocumentStoreFixed(host=host, port=port, username=es_username, password=es_password,\n",
    "                                                 scheme=\"https\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}