{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "difficult-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peripheral-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, save_json, BASE_DATA_DIR\n",
    "from twitter_requests import TwitterApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daily-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-option",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caring-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_api = TwitterApi(timeline_params_path=\"timeline_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unexpected-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = pd.read_csv(os.path.join(BASE_DATA_DIR, \"twitter_data/candidates_20210721.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cc58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates_df = pd.concat([candidates_df, pd.DataFrame([candidate])], axis=0).reset_index(drop=True)\n",
    "# candidates_df.to_csv(os.path.join(BASE_DATA_DIR, \"twitter_data/candidates_20210721.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "middle-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_folder_path = os.path.join(BASE_DATA_DIR, \"twitter_data/raw_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complete-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Weidel\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1966956cb4a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtwitter_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_user_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweet_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ama_tweet_fetcher/src/twitter_requests.py\u001b[0m in \u001b[0;36mbuild_user_dataset\u001b[0;34m(self, user_name, params, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m         user_id = self.query_user_data_by_name(\n\u001b[1;32m     29\u001b[0m             user_name, params={\"user.fields\": \"id\"})[\"id\"]\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtweets\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ama_tweet_fetcher/src/twitter_requests.py\u001b[0m in \u001b[0;36mget_user_tweets\u001b[0;34m(self, user_id, params)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtimeline_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         json_response = self.connect_to_endpoint(\n\u001b[0;32m---> 55\u001b[0;31m             url, self.headers, timeline_params)\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next_token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "for i, row in candidates_df.iterrows():\n",
    "    print(row.full_name)\n",
    "    twitter_api.build_user_dataset(row.twitter_name, data_dir=tweet_folder_path)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-omaha",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acceptable-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expected-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_files = glob(f\"{tweet_folder_path}/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expensive-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = []\n",
    "\n",
    "for filepath in twitter_files:\n",
    "    twitter_data.extend(load_json(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regulated-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.DataFrame(twitter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "excessive-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"author_id\"] = twitter_df.author_id.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da95ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df[\"author_id\"] = candidates_df.twitter_name.map(lambda x: str(twitter_api.query_user_data_by_name(x)[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broad-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.merge(\n",
    "    left=twitter_df,\n",
    "    right=candidates_df,\n",
    "    on=\"author_id\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707b32d",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet_preprocessing import normalize_mentions, normalize_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7065a0",
   "metadata": {},
   "source": [
    "## Normalize user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46234dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name_mapping_path = os.path.join(BASE_DATA_DIR, \"twitter_data/user_name_mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0e6656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec3c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_name_mapping_path, \"r\") as f:\n",
    "    mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4105cc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with mention 'dna4287'.\n"
     ]
    }
   ],
   "source": [
    "normalize_mentions(twitter_df, twitter_api, user_name_mapping_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440ec82",
   "metadata": {},
   "source": [
    "## Normalize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea22453",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_mapping = {\n",
    "    \"#\": \"\",\n",
    "    \"BuReg\": \"Bundesregierung\",\n",
    "    \"🇩🇪\": \"Deutschland\",\n",
    "    \"&amp;\": \"und\",\n",
    "    r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a276fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"cleaned_text\"] = twitter_df.cleaned_text.map(lambda x: normalize_tokens(x, token_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5144fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_artefact_mapping = {\n",
    "    \"&amp;\": \"&\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2863b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"text\"] = twitter_df.text.map(lambda x: normalize_tokens(x, html_artefact_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4086b",
   "metadata": {},
   "source": [
    "# Normalize party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f5643f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df[\"party\"] = twitter_df.party.map(lambda x: \"CDU/CSU\" if x in [\"CDU\", \"CSU\"] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d951fc5",
   "metadata": {},
   "source": [
    "# Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a37da69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5f50e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "file_name = f\"twitter_df_{current_date}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cosmetic-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_pickle(os.path.join(BASE_DATA_DIR, f\"twitter_data/processed_datasets/{file_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03883741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df = pd.read_pickle(os.path.join(BASE_DATA_DIR, f\"twitter_data/processed_datasets/{file_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2658af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
